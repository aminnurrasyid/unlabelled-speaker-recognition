{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d781dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6894c",
   "metadata": {},
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7210aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "DURATION = 3\n",
    "AUDIO_DIR_PATH = \"audio\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b36cf",
   "metadata": {},
   "source": [
    "Load audio and load it into raw waveforms segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37127b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_file_name in os.listdir(AUDIO_DIR_PATH):    \n",
    "    waveform, sr = librosa.load(os.path.join(AUDIO_DIR_PATH, audio_file_name), sr=SAMPLE_RATE)\n",
    "    total_samples = DURATION * SAMPLE_RATE \n",
    "    segments = []\n",
    "    for i in range(0, len(waveform) - total_samples + 1, total_samples):\n",
    "        segments.append(waveform[i:i + total_samples]) # last incomplete segment will be excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8e002",
   "metadata": {},
   "source": [
    "Spectograms Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf35bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0883aec5",
   "metadata": {},
   "source": [
    "Prosodic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56880b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment in segments:\n",
    "\n",
    "    # 1. Pitch (using YIN)\n",
    "    pitch = librosa.yin(segment, fmin=50, fmax=300, sr=sr)\n",
    "    # 2. Energy (RMS)\n",
    "    energy = librosa.feature.rms(y=segment)[0]\n",
    "    # 3. Speaking rate (rough proxy using tempo)\n",
    "    tempo, _ = librosa.beat.beat_track(y=segment, sr=sr)\n",
    "    # Frame-align pitch & energy (zero-pad to same length)\n",
    "    length = min(len(pitch), len(energy))\n",
    "    pitch = pitch[:length]\n",
    "    energy = energy[:length]\n",
    "    # Combine frame-wise\n",
    "    features = np.stack([pitch, energy], axis=1)  # [T x 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15e832",
   "metadata": {},
   "source": [
    "Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e9ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
